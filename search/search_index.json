{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Meshroom \u00b6 A command-line tool to build and manage Cybersecurity Mesh Architectures (CSMA). Overview \u00b6 As defined by Gartner, a Cybersecurity Mesh Architecture is a graph of interoperated cybersecurity services, each fulfilling a specific functional need (SIEM, EDR, EASM, XDR, TIP, etc ). Adopting the CSMA and Meshroom's philosophy means choosing an interconnected ecosystem of high-quality products with specialized scopes rather than a captive all-in-one solution. It then means : Adopting standard formats and protocols rather than proprietary ones to share data and information between products (OCSF, STIX, ECS, OpenC2, syslog, CEF, etc ) Leveraging Open APIs to make your products communicate and interact eachother Exploiting products' extensibility via plugins and open-source components to encourage user-defined interoperability Audience \u00b6 As a vendor : fight the N-to-N integration curse \u00b6 Cybersecurity vendors know it well : integrating with other cybersecurity products burns time and human resources . Integration teams feel so sad when every vendor has to spend those resources developing an integration with every other vendor, without work factorization : this is the N-to-N integration curse . This curse mostly originates from: Poor adoption of standard formats, protocols and API layouts to interoperate cybersecurity solutions Lack of open resources and documentation to start communicating and controling a given product Small actors are overwhelmed by the numerous integration opportunities with major actors, but won't factorise their contributions to make one integration suit all 3rd-party products Every actor must keep hundreds of vendor-specific integrations up to date according to hundreds of non-coordinated roadmaps and constantly breaking changes Meshroom helps cybersecurity vendors build integrations between their products and other solutions, keeping the integration burden as low a possible. To do so, meshroom comes with a set of predefined product templates aligned with different market analyst categories that help the vendor to align its product integration with full category scope. If you are this vendor, by publishing your product's functional surface from one of this template, you encourage the adoption of open API layouts, formats and protocols. Whereby, you contributes to turn the N-to-N integration burden into an ideal repository of N reusable product definitions , where every new vendor can effortlessly plug with the N previously declared products. As a MSSP/MDR : setup a full cybersecurity mesh via declarative and versionable manifests \u00b6 Setting up a SOC is also a time-consuming operation. Sadly, MSSPs in charge of many similar information systems will often repeat those very same time-consuming steps again and again, switching from one solution's configuration interface to another one's admin console. Eventually, this will involve wildly manipulating API keys and admin forms, resulting in errors, security holes and blind spots. Many MSSPs maintain a run book of manual setup steps, and most of them automate part of those steps to get a SOC up-and-running within hours or days. Meshroom helps DevSec operators to setup a full meshed SOC made of dozens of tenants in a single CLI command : meshroom up . Because Meshroom projects are versioned , you can push and share SOC architectures via GitHub or your favorite forge, while keeping trace of every setup and provisioning processes executed. You can think of meshroom up as the cyber mesh equivalent of Infrastructure-as-code's terraform apply or containerized stack's docker compose up . When your SOC grows to dozens of interoperated products, it becomes hard to visualize where data and controls flow between them. Meshroom provides an easy to use graph model documenting: all capabilities exposed by the products you are using all available integrations they offer to other products all the active connections (know as Plugs within Meshroom) between products (aka producer / consumer and trigger / executor relationships) As a developer : painless developer experience to build and publish custom product additions \u00b6 Many cybersecurity platforms offer extensible capabilities via plugins , custom formats, custom rules, custom actions, etc . Here again, there's no accepted standard and each vendor defines its own approach (YAML files, python code, no-code workflows, etc ). Yet, products interoperability often rely on contributing custom additions to one or both ends. Of course, this scope is often badly documented, and developers are left with trial-and-error quasi-reverse ninja approaches to understand how to make product A talk to product B. In the end, you'll eventually succeed in getting a working plugin, but then face the un-coordinated maze of homologation processes each vendor mandates to make your contribution public . Meshroom helps cybersecurity vendors to expose a single standard contribution model for: setting up custom software additions when interoperability mandates so compiling everything into a product plugin suitable for publication publishing as a PR to GitHub or other marketplaces Meshroom also eases the tedious \"playground\" phase where developers need to send test data to their trial 3rd-party instances, trigger remote commands from their workstation, watch results, make changes to their integration in an agile continous development workflow: meshroom produce helps you sending data through plugged integrations meshroom watch helps you watching data flowing through a plugged integration","title":"Meshroom"},{"location":"#meshroom","text":"A command-line tool to build and manage Cybersecurity Mesh Architectures (CSMA).","title":"Meshroom"},{"location":"#overview","text":"As defined by Gartner, a Cybersecurity Mesh Architecture is a graph of interoperated cybersecurity services, each fulfilling a specific functional need (SIEM, EDR, EASM, XDR, TIP, etc ). Adopting the CSMA and Meshroom's philosophy means choosing an interconnected ecosystem of high-quality products with specialized scopes rather than a captive all-in-one solution. It then means : Adopting standard formats and protocols rather than proprietary ones to share data and information between products (OCSF, STIX, ECS, OpenC2, syslog, CEF, etc ) Leveraging Open APIs to make your products communicate and interact eachother Exploiting products' extensibility via plugins and open-source components to encourage user-defined interoperability","title":"Overview"},{"location":"#audience","text":"","title":"Audience"},{"location":"#as-a-vendor-fight-the-n-to-n-integration-curse","text":"Cybersecurity vendors know it well : integrating with other cybersecurity products burns time and human resources . Integration teams feel so sad when every vendor has to spend those resources developing an integration with every other vendor, without work factorization : this is the N-to-N integration curse . This curse mostly originates from: Poor adoption of standard formats, protocols and API layouts to interoperate cybersecurity solutions Lack of open resources and documentation to start communicating and controling a given product Small actors are overwhelmed by the numerous integration opportunities with major actors, but won't factorise their contributions to make one integration suit all 3rd-party products Every actor must keep hundreds of vendor-specific integrations up to date according to hundreds of non-coordinated roadmaps and constantly breaking changes Meshroom helps cybersecurity vendors build integrations between their products and other solutions, keeping the integration burden as low a possible. To do so, meshroom comes with a set of predefined product templates aligned with different market analyst categories that help the vendor to align its product integration with full category scope. If you are this vendor, by publishing your product's functional surface from one of this template, you encourage the adoption of open API layouts, formats and protocols. Whereby, you contributes to turn the N-to-N integration burden into an ideal repository of N reusable product definitions , where every new vendor can effortlessly plug with the N previously declared products.","title":"As a vendor : fight the N-to-N integration curse"},{"location":"#as-a-msspmdr-setup-a-full-cybersecurity-mesh-via-declarative-and-versionable-manifests","text":"Setting up a SOC is also a time-consuming operation. Sadly, MSSPs in charge of many similar information systems will often repeat those very same time-consuming steps again and again, switching from one solution's configuration interface to another one's admin console. Eventually, this will involve wildly manipulating API keys and admin forms, resulting in errors, security holes and blind spots. Many MSSPs maintain a run book of manual setup steps, and most of them automate part of those steps to get a SOC up-and-running within hours or days. Meshroom helps DevSec operators to setup a full meshed SOC made of dozens of tenants in a single CLI command : meshroom up . Because Meshroom projects are versioned , you can push and share SOC architectures via GitHub or your favorite forge, while keeping trace of every setup and provisioning processes executed. You can think of meshroom up as the cyber mesh equivalent of Infrastructure-as-code's terraform apply or containerized stack's docker compose up . When your SOC grows to dozens of interoperated products, it becomes hard to visualize where data and controls flow between them. Meshroom provides an easy to use graph model documenting: all capabilities exposed by the products you are using all available integrations they offer to other products all the active connections (know as Plugs within Meshroom) between products (aka producer / consumer and trigger / executor relationships)","title":"As a MSSP/MDR : setup a full cybersecurity mesh via declarative and versionable manifests"},{"location":"#as-a-developer-painless-developer-experience-to-build-and-publish-custom-product-additions","text":"Many cybersecurity platforms offer extensible capabilities via plugins , custom formats, custom rules, custom actions, etc . Here again, there's no accepted standard and each vendor defines its own approach (YAML files, python code, no-code workflows, etc ). Yet, products interoperability often rely on contributing custom additions to one or both ends. Of course, this scope is often badly documented, and developers are left with trial-and-error quasi-reverse ninja approaches to understand how to make product A talk to product B. In the end, you'll eventually succeed in getting a working plugin, but then face the un-coordinated maze of homologation processes each vendor mandates to make your contribution public . Meshroom helps cybersecurity vendors to expose a single standard contribution model for: setting up custom software additions when interoperability mandates so compiling everything into a product plugin suitable for publication publishing as a PR to GitHub or other marketplaces Meshroom also eases the tedious \"playground\" phase where developers need to send test data to their trial 3rd-party instances, trigger remote commands from their workstation, watch results, make changes to their integration in an agile continous development workflow: meshroom produce helps you sending data through plugged integrations meshroom watch helps you watching data flowing through a plugged integration","title":"As a developer : painless developer experience to build and publish custom product additions"},{"location":"concepts/","text":"Concepts \u00b6 Integration lifecycle \u00b6 TODO CYCLE SCHEMA Capability graph \u00b6 Formally, a cybersecurity mesh architecture (CSMA) is a directed graph of products talking to eachother. More precisely, it is an overlay of 2 graphs: The capability graph , which expresses the set of all products that can be interoperated with eachother and what functional capacities they expose. Nodes of this graph are Product capabilities, and edges connect complementary capabilities. For example, one product may consume alerts produced by another product, or can execute actions triggered by another one. Edges thus characterise interop opportunities about a certain Topic between a source product and a destination product. The direction of the edges materializes the dataflow : the source product produces/triggers information (resp. actions) that the destination product consumes/executes . An edge exists as soon as the products define a compatible producer (or trigger) / consumer (resp. executor) pair of Integrations . The edge also carries the roles in the data exchange in push mode, the producer is active and the consumer is passive ( e.g. a Syslog forwarder) in pull mode, the producer is passive and the consumer is active ( e.g. an HTTP GET API) Therefore, an edge exists between product couples that expose complementary integrations for compatible topics, and match formats (or other compatibility criteria you want to refine within the scope of a capability). The density if the capability graph measures the \"openness\" of the products constellation ; one wants to maximize the number of allowed interops between cybersecurity solutions available on the market The Mesh graph itself, which means several product Instances connected to eachother by Plugs which leverage compatible Integrations over the underlying capability graph. Instances correspond to actual user tenants of the underlying products, and plugs are live connections between those tenants. In order to setup the defined plugs, instances must be configured to enable the corresponding production/consumption triggering/execution logic, potentially via custom additions to the products themselves. Meshroom's spirit is to make all this configuration and provisioning as simple as a single meshroom up command. To do so, Products, Integrations, Instances and Plugs are defined via YAML manifests and vendor code additions when required. All these files belong to a git-backed repository that can be shared, versioned via git and manipulated via the Meshroom CLI (similar with Helm charts being shared among a community of Kubernetes users). Sensitive data, like API keys and other secrets used to teleoperate the Instances is natively managed by Meshroom in a local GPG secrets store . This store can also be shared, like any other GPG content, with GPG peers. This fosters the sharing of a SOC-as-code and limits the risk of information leakage. Project \u00b6 A Meshroom Project is a git-backed local directory on your computer, based on a file structure. Meshroom CLI handles this structure (see Meshroom project structure ). You can start a new meshroom project via meshroom init <path> . This will setup a new local git repo and few minimal files in this directory so that you can start building your integrations and mesh architecture. You can then directly add a git remote via git remote add <remote> <remote_url> such as a GitHub repository to save, share and publish your project via git push , and use the directory as a classical Git repository. Subsequent meshroom commands must be executed at the <path> 's root and will manipulate its files hierarchy. Product \u00b6 In Meshroom, a Product is the definition of a cybersecurity product's capabilities. A Product is primarily defined via a YAML file with: a name a textual description of its functional surface and its role in the security ecosystem a set of tags , expliciting the product category it belongs to ( e.g. , EDR, EASM, SIEM, etc) a produces attribute listing the producer capabilities of the product (which topics the product is able to produce data for) a consumes attribute, listing the consumer capabilities of the product a triggers attribute, listing the trigger capabilities of the product a executes attribute, listing the executor capabilities of the product Here is an example of consumer capability: ... consumes: events: - mode: pull format: ECS - mode: push format: syslog ... This YAML strip tells that the product can consume the events topic in pull mode (aka active consumer, passive producer, as in HTTP GET) when events are formatted using ECS, and can consume events in push mode (aka passive consumer, active produver, as in syslog forwarding) as Syslog lines. Capabilities may be more generic ( e.g. no format constraint) or more specific ( e.g. add a protocol constraint to match). In all cases, two Products are said \"interoperable\" when they both have corresponding capabilities of complementary role ( consumes -> produces or triggers -> executes ) of identical topic (\"events\" here) of matching constraints (mode, format, etc). When a constraint is unset, the capability is considered \"always matching\" ( e.g an ECS events producer will match a events consumer whose format is unset) Ideally, every product should define their full functional surface (incoming and outgoing data feeds, remote API commands, etc) with appropriate constraints to clearly state their complete interop potential. This can be cumbersome, so Meshroom comes with a predefined set of Product Templates to scaffold your own product. The product templates catalog is based on Gartner's \"Hype Cycle for Security Operations 2024\" and tries to cover the critical capabilities of these products, but feel free to contribute new templates if you feel we missed some product categories. To create a new product in your Meshroom project, simply use the meshroom create product command. You may base your product on an existing template via meshroom create product --from <template> You can list and search available products in the current project via meshroom list products Integration \u00b6 To be interoperable, most product capabilities can't just be declared, some must be programmatically configured, some even involve pushing custom code or calling multiple APIs to get up-and-running. The recipe of setting up a consumer/producer/trigger/executor capability on a product is termed an Integration . Some Integrations will simply be implicitly rendered by their product's YAML manifest. For example, an exposed HTTP GET API at a given URL is fully described by its HTTP nature, the method used, the endpoint's URL and accepted path and query params. As in an Open API manifest, this information is enough to interconnect with a 3rd-party. Integrations that require specific configuration procedures can be explicitly defined via python hooks (see Hooks ) in the product's integrations folders. Python files insides those folders are automatically interpreted and used when calling meshroom up to know how to configure each end of a Plug edge, yielding an up-and-running interop between both products. Whithin Meshroom, Products A an B are said interoperable when either: * A defines an integration with B and B defines an integration with A , both defining a @setup Hook. In this scenario, A and B are considered responsible for setting up their end of the edge. * A or B defines a @setup Hook with owns_both=True' . In this scenario, a single instance will take care of setting up the full interconnection, without requiring any provisioning from the other end (this is typically the case for API endpoints, which by design don't need to be \"configured\"). A couple of Products exposing complementary capabilities is thus considered theoretically interoperable but since none provides a @setup hook, Meshroom doesn't know how to concretely setup the interconnection. You can create an integration via meshroom create integration <product> <target_product> <topic> [options...] You can see that an integration is always about a specific topic. If a given product endpoint serves multiple purposes, you shall define as many Integrations as necessary to cover the actual functional scope of it. You can list and search among existing integrations using meshroom list integrations Instance \u00b6 Once your project defines a Capability Graph of Products and Integrations , you're ready to define a Mesh architecture by picking up among its allowed nodes and edges. In a mesh, nodes are called Instances and edges are called Plugs You can add a new instance of a given product using meshroom add <product> [instance_name] If the product declares required settings (like API keys, cloud region, URL, etc), you will be asked for their values, interactively. Fields declared as secrets in the product's YAML manifest will be securely stored in the project's GPG store. You can list defined instances using meshroom list instances And (re-)configure settings for an instance using meshroom configure <instance_name> Your project's Instances and GPG store form a handy bundle of your full SOC's product constellation, versioning and securely storing all the necessary material to administrate and interoperate this ecosystem in a well-defined hierarchy. Plug \u00b6 Instances communicate with eachother via so-called Plugs . Plugs are the edge of your mesh's graph. A Plug makes use of: a source Integration on the source product at the edge's origin a destination Integration on the destination product at the opposite end. A Plug always carries a single topic, in a single mode. When setting up a Plug using 2 integrations, the plug inherits its format and other constraints from the most specific combination of both integrations' constraints. When no matching constraint set can be found out of all existing Integrations, the Plug can't be created and the two product instances won't be able to communicate. You can then build new integration, perhaps more generic, to cover your desired Plug's need, on one or both ends of the edge (see Integration ). You can plug two Instances using meshroom plug <topic> <source_instance> <destination_instance> [options...] and unplug an existing plug using meshroom unplug <topic> <source_instance> <destination_instance> [options...] Note that there can only be one plug at a time for each set of constraints. You can get several plugs on the same Instances pair for the same topic by narrowing their constraint sets. You can list and search plugs using meshroom list plugs Up/down \u00b6 Once your mesh is defined, you can apply it to your real product tenants via a single command: meshroom up The opposite operation being meshroom down Like in docker compose (for those familiar with it), up/down is the core value of Meshroom : it allows to configure a full mesh in a single call, that will be resolved by Meshroom CLI to a sequence of configuration operations submitted to your Instances based on the defined settings, secrets and Plugs. Ideally, you won't ever need to switch to your products' admin consoles. You may then assess the quality of your mesh interop via meshroom produce and meshroom watch commands, that respectively helps you producing and inspecting data flowing through your plugs. Hooks \u00b6 Many products require complex programmatic steps to setup an actual interop with a 3rd-party. The classical approach is to follow manual recipes from the products documentation, navigate through multiple admin panels and configuration forms to open the desired channel between two products. One of the main goals of Meshroom is to rationalize and fully automate these steps, so that meshroom up can submit the appropriate sequence of operations to all instances to configure the full mesh without direct user intervention. Willingness to favor remote tenant configuration via open APIs vary across vendors and solutions. Some products are simply not remote-configurable at all (think of adding syslog forwarding to an unexposed NGINX reverse-proxy). Others may require a very short but mandatory user navigation to their admin panel. Hopefully, more and more vendors embrace the CSMA approach and allow for completely remote configuration by 3rd-party providers. Meshroom takes into account those various regimes by allowing Products to define python hooks. Hooks are python decorated functions that will get executed in sequence upon meshroom up , taking the whole integration's context as arguments. Vendors and integrators can provide such hooks to implement automated procedures to remote-configure their product's capabilities. You can even provide boilerplate hooks to help user scaffold new integrations based on the products native extensibility features (plugins, custom formats, code addtions, etc ), and publish hooks to guide the user through the vendor's homologation process required to publish their contribution into the product's official integrations catalog (marketplace, github PRs, etc ). Hooks use vanilla python functions decorators residing either inside the product's directory (for product-wide generic hooks) a specific integration's subdirectory (for plug-specific hooks that depend on a specific products couple) via one of the decorators defined in the meshroom.decorators package: hook decorator called upon usage required @setup meshroom up define an automated setup step to get a plug up-and-running on a given instance optional @teardown meshroom down define an automated step to shutdown and cleanup a plug from a given instance optional @scaffold meshroom create integration generate files for a new integration for a certain topic optional @pull meshroom pull generate integrations by pulling the vendor's online integration catalog required @publish meshroom publish submit all defined integrations to the vendor's catalog for public homologation required @produce meshroom produce send data to the plug's destination for testing required @watch meshroom watch inspect data flowing through the plug required Hooks may specify an order (an integer or 'first'/'last' keywords) field to order the setup sequence. Hooks marked as \"required\" are required for the corresponding Meshroom command to work on the said product. They are not mandatory for a product definition to be valid, but not all meshroom command will be available until these hooks are implemented. Wrap-up with Meshroom project structure \u00b6 A Meshroom project is a git-backed directory on your computer, that you can version and share via your favorite online git service. The local project itself has the following structure: \u2503 \u2523\u2501 products \ud83e\udfa4\u2501\u2501\u2501 All products available in the capabilities graph \u2503 \u2517\u2501 product_a \u2503 \u2523\u2501 definition.yaml \ud83e\udfa4\u2501\u2501\u2501 Define capabilities of product_a \u2503 \u2523\u2501 setup.py \ud83e\udfa4\u2501\u2501\u2501 Various python files with generic hooks for product_a's integrations \u2503 \u2517\u2501 integrations \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a \u2503 \u2517\u2501 product_b \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a with product_b \u2503 \u2523\u2501 events_consumer.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in push mode \u2503 \u2523\u2501 events_consumer.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for the above integration \u2503 \u2523\u2501 events_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in pull mode \u2503 \u2517\u2501 events_consumer_pull.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for this latter integration \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 ... \ud83e\udfa4\u2501\u2501\u2501 same structure for each product... \u2503 \u2523\u2501 instances \ud83e\udfa4\u2501\u2501\u2501 Define the instances used in this project's mesh \u2503 \u2517\u2501 product_a \ud83e\udfa4\u2501\u2501\u2501 Instances for product_a \u2503 \u2517\u2501 instance_a \ud83e\udfa4\u2501\u2501\u2501 Some product_a's instance, here called \"instance_a\" \u2503 \u2523\u2501 config.yaml \ud83e\udfa4\u2501\u2501\u2501 Non-sensitive configuration for instance_a \u2503 \u2517\u2501 plugs \ud83e\udfa4\u2501\u2501\u2501 Plugs whose source is instance_a \u2503 \u2517\u2501 instance_b \ud83e\udfa4\u2501\u2501\u2501 Plugs whose destination is instance_b \u2503 \u2517\u2501 event_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 Config for plug instance_a -[events]-> instance_b in pull mode \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 instance_product_b \u2503 \u2517\u2501 ... \u2523\u2501 secrets.gpg \ud83e\udfa4\u2501\u2501\u2501 GPG-encrypted store of all instances' secrets This is a minimal example, your project may contain additional files, such as .gitignore, README.md and other documentation or scripts for automating stuff.","title":"Concepts"},{"location":"concepts/#concepts","text":"","title":"Concepts"},{"location":"concepts/#integration-lifecycle","text":"TODO CYCLE SCHEMA","title":"Integration lifecycle"},{"location":"concepts/#capability-graph","text":"Formally, a cybersecurity mesh architecture (CSMA) is a directed graph of products talking to eachother. More precisely, it is an overlay of 2 graphs: The capability graph , which expresses the set of all products that can be interoperated with eachother and what functional capacities they expose. Nodes of this graph are Product capabilities, and edges connect complementary capabilities. For example, one product may consume alerts produced by another product, or can execute actions triggered by another one. Edges thus characterise interop opportunities about a certain Topic between a source product and a destination product. The direction of the edges materializes the dataflow : the source product produces/triggers information (resp. actions) that the destination product consumes/executes . An edge exists as soon as the products define a compatible producer (or trigger) / consumer (resp. executor) pair of Integrations . The edge also carries the roles in the data exchange in push mode, the producer is active and the consumer is passive ( e.g. a Syslog forwarder) in pull mode, the producer is passive and the consumer is active ( e.g. an HTTP GET API) Therefore, an edge exists between product couples that expose complementary integrations for compatible topics, and match formats (or other compatibility criteria you want to refine within the scope of a capability). The density if the capability graph measures the \"openness\" of the products constellation ; one wants to maximize the number of allowed interops between cybersecurity solutions available on the market The Mesh graph itself, which means several product Instances connected to eachother by Plugs which leverage compatible Integrations over the underlying capability graph. Instances correspond to actual user tenants of the underlying products, and plugs are live connections between those tenants. In order to setup the defined plugs, instances must be configured to enable the corresponding production/consumption triggering/execution logic, potentially via custom additions to the products themselves. Meshroom's spirit is to make all this configuration and provisioning as simple as a single meshroom up command. To do so, Products, Integrations, Instances and Plugs are defined via YAML manifests and vendor code additions when required. All these files belong to a git-backed repository that can be shared, versioned via git and manipulated via the Meshroom CLI (similar with Helm charts being shared among a community of Kubernetes users). Sensitive data, like API keys and other secrets used to teleoperate the Instances is natively managed by Meshroom in a local GPG secrets store . This store can also be shared, like any other GPG content, with GPG peers. This fosters the sharing of a SOC-as-code and limits the risk of information leakage.","title":"Capability graph"},{"location":"concepts/#project","text":"A Meshroom Project is a git-backed local directory on your computer, based on a file structure. Meshroom CLI handles this structure (see Meshroom project structure ). You can start a new meshroom project via meshroom init <path> . This will setup a new local git repo and few minimal files in this directory so that you can start building your integrations and mesh architecture. You can then directly add a git remote via git remote add <remote> <remote_url> such as a GitHub repository to save, share and publish your project via git push , and use the directory as a classical Git repository. Subsequent meshroom commands must be executed at the <path> 's root and will manipulate its files hierarchy.","title":"Project"},{"location":"concepts/#product","text":"In Meshroom, a Product is the definition of a cybersecurity product's capabilities. A Product is primarily defined via a YAML file with: a name a textual description of its functional surface and its role in the security ecosystem a set of tags , expliciting the product category it belongs to ( e.g. , EDR, EASM, SIEM, etc) a produces attribute listing the producer capabilities of the product (which topics the product is able to produce data for) a consumes attribute, listing the consumer capabilities of the product a triggers attribute, listing the trigger capabilities of the product a executes attribute, listing the executor capabilities of the product Here is an example of consumer capability: ... consumes: events: - mode: pull format: ECS - mode: push format: syslog ... This YAML strip tells that the product can consume the events topic in pull mode (aka active consumer, passive producer, as in HTTP GET) when events are formatted using ECS, and can consume events in push mode (aka passive consumer, active produver, as in syslog forwarding) as Syslog lines. Capabilities may be more generic ( e.g. no format constraint) or more specific ( e.g. add a protocol constraint to match). In all cases, two Products are said \"interoperable\" when they both have corresponding capabilities of complementary role ( consumes -> produces or triggers -> executes ) of identical topic (\"events\" here) of matching constraints (mode, format, etc). When a constraint is unset, the capability is considered \"always matching\" ( e.g an ECS events producer will match a events consumer whose format is unset) Ideally, every product should define their full functional surface (incoming and outgoing data feeds, remote API commands, etc) with appropriate constraints to clearly state their complete interop potential. This can be cumbersome, so Meshroom comes with a predefined set of Product Templates to scaffold your own product. The product templates catalog is based on Gartner's \"Hype Cycle for Security Operations 2024\" and tries to cover the critical capabilities of these products, but feel free to contribute new templates if you feel we missed some product categories. To create a new product in your Meshroom project, simply use the meshroom create product command. You may base your product on an existing template via meshroom create product --from <template> You can list and search available products in the current project via meshroom list products","title":"Product"},{"location":"concepts/#integration","text":"To be interoperable, most product capabilities can't just be declared, some must be programmatically configured, some even involve pushing custom code or calling multiple APIs to get up-and-running. The recipe of setting up a consumer/producer/trigger/executor capability on a product is termed an Integration . Some Integrations will simply be implicitly rendered by their product's YAML manifest. For example, an exposed HTTP GET API at a given URL is fully described by its HTTP nature, the method used, the endpoint's URL and accepted path and query params. As in an Open API manifest, this information is enough to interconnect with a 3rd-party. Integrations that require specific configuration procedures can be explicitly defined via python hooks (see Hooks ) in the product's integrations folders. Python files insides those folders are automatically interpreted and used when calling meshroom up to know how to configure each end of a Plug edge, yielding an up-and-running interop between both products. Whithin Meshroom, Products A an B are said interoperable when either: * A defines an integration with B and B defines an integration with A , both defining a @setup Hook. In this scenario, A and B are considered responsible for setting up their end of the edge. * A or B defines a @setup Hook with owns_both=True' . In this scenario, a single instance will take care of setting up the full interconnection, without requiring any provisioning from the other end (this is typically the case for API endpoints, which by design don't need to be \"configured\"). A couple of Products exposing complementary capabilities is thus considered theoretically interoperable but since none provides a @setup hook, Meshroom doesn't know how to concretely setup the interconnection. You can create an integration via meshroom create integration <product> <target_product> <topic> [options...] You can see that an integration is always about a specific topic. If a given product endpoint serves multiple purposes, you shall define as many Integrations as necessary to cover the actual functional scope of it. You can list and search among existing integrations using meshroom list integrations","title":"Integration"},{"location":"concepts/#instance","text":"Once your project defines a Capability Graph of Products and Integrations , you're ready to define a Mesh architecture by picking up among its allowed nodes and edges. In a mesh, nodes are called Instances and edges are called Plugs You can add a new instance of a given product using meshroom add <product> [instance_name] If the product declares required settings (like API keys, cloud region, URL, etc), you will be asked for their values, interactively. Fields declared as secrets in the product's YAML manifest will be securely stored in the project's GPG store. You can list defined instances using meshroom list instances And (re-)configure settings for an instance using meshroom configure <instance_name> Your project's Instances and GPG store form a handy bundle of your full SOC's product constellation, versioning and securely storing all the necessary material to administrate and interoperate this ecosystem in a well-defined hierarchy.","title":"Instance"},{"location":"concepts/#plug","text":"Instances communicate with eachother via so-called Plugs . Plugs are the edge of your mesh's graph. A Plug makes use of: a source Integration on the source product at the edge's origin a destination Integration on the destination product at the opposite end. A Plug always carries a single topic, in a single mode. When setting up a Plug using 2 integrations, the plug inherits its format and other constraints from the most specific combination of both integrations' constraints. When no matching constraint set can be found out of all existing Integrations, the Plug can't be created and the two product instances won't be able to communicate. You can then build new integration, perhaps more generic, to cover your desired Plug's need, on one or both ends of the edge (see Integration ). You can plug two Instances using meshroom plug <topic> <source_instance> <destination_instance> [options...] and unplug an existing plug using meshroom unplug <topic> <source_instance> <destination_instance> [options...] Note that there can only be one plug at a time for each set of constraints. You can get several plugs on the same Instances pair for the same topic by narrowing their constraint sets. You can list and search plugs using meshroom list plugs","title":"Plug"},{"location":"concepts/#updown","text":"Once your mesh is defined, you can apply it to your real product tenants via a single command: meshroom up The opposite operation being meshroom down Like in docker compose (for those familiar with it), up/down is the core value of Meshroom : it allows to configure a full mesh in a single call, that will be resolved by Meshroom CLI to a sequence of configuration operations submitted to your Instances based on the defined settings, secrets and Plugs. Ideally, you won't ever need to switch to your products' admin consoles. You may then assess the quality of your mesh interop via meshroom produce and meshroom watch commands, that respectively helps you producing and inspecting data flowing through your plugs.","title":"Up/down"},{"location":"concepts/#hooks","text":"Many products require complex programmatic steps to setup an actual interop with a 3rd-party. The classical approach is to follow manual recipes from the products documentation, navigate through multiple admin panels and configuration forms to open the desired channel between two products. One of the main goals of Meshroom is to rationalize and fully automate these steps, so that meshroom up can submit the appropriate sequence of operations to all instances to configure the full mesh without direct user intervention. Willingness to favor remote tenant configuration via open APIs vary across vendors and solutions. Some products are simply not remote-configurable at all (think of adding syslog forwarding to an unexposed NGINX reverse-proxy). Others may require a very short but mandatory user navigation to their admin panel. Hopefully, more and more vendors embrace the CSMA approach and allow for completely remote configuration by 3rd-party providers. Meshroom takes into account those various regimes by allowing Products to define python hooks. Hooks are python decorated functions that will get executed in sequence upon meshroom up , taking the whole integration's context as arguments. Vendors and integrators can provide such hooks to implement automated procedures to remote-configure their product's capabilities. You can even provide boilerplate hooks to help user scaffold new integrations based on the products native extensibility features (plugins, custom formats, code addtions, etc ), and publish hooks to guide the user through the vendor's homologation process required to publish their contribution into the product's official integrations catalog (marketplace, github PRs, etc ). Hooks use vanilla python functions decorators residing either inside the product's directory (for product-wide generic hooks) a specific integration's subdirectory (for plug-specific hooks that depend on a specific products couple) via one of the decorators defined in the meshroom.decorators package: hook decorator called upon usage required @setup meshroom up define an automated setup step to get a plug up-and-running on a given instance optional @teardown meshroom down define an automated step to shutdown and cleanup a plug from a given instance optional @scaffold meshroom create integration generate files for a new integration for a certain topic optional @pull meshroom pull generate integrations by pulling the vendor's online integration catalog required @publish meshroom publish submit all defined integrations to the vendor's catalog for public homologation required @produce meshroom produce send data to the plug's destination for testing required @watch meshroom watch inspect data flowing through the plug required Hooks may specify an order (an integer or 'first'/'last' keywords) field to order the setup sequence. Hooks marked as \"required\" are required for the corresponding Meshroom command to work on the said product. They are not mandatory for a product definition to be valid, but not all meshroom command will be available until these hooks are implemented.","title":"Hooks"},{"location":"concepts/#wrap-up-with-meshroom-project-structure","text":"A Meshroom project is a git-backed directory on your computer, that you can version and share via your favorite online git service. The local project itself has the following structure: \u2503 \u2523\u2501 products \ud83e\udfa4\u2501\u2501\u2501 All products available in the capabilities graph \u2503 \u2517\u2501 product_a \u2503 \u2523\u2501 definition.yaml \ud83e\udfa4\u2501\u2501\u2501 Define capabilities of product_a \u2503 \u2523\u2501 setup.py \ud83e\udfa4\u2501\u2501\u2501 Various python files with generic hooks for product_a's integrations \u2503 \u2517\u2501 integrations \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a \u2503 \u2517\u2501 product_b \ud83e\udfa4\u2501\u2501\u2501 All integration offered by product_a with product_b \u2503 \u2523\u2501 events_consumer.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in push mode \u2503 \u2523\u2501 events_consumer.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for the above integration \u2503 \u2523\u2501 events_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 An integration product_a -[events]-> product_b in pull mode \u2503 \u2517\u2501 events_consumer_pull.py \ud83e\udfa4\u2501\u2501\u2501 Hooks for this latter integration \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 ... \ud83e\udfa4\u2501\u2501\u2501 same structure for each product... \u2503 \u2523\u2501 instances \ud83e\udfa4\u2501\u2501\u2501 Define the instances used in this project's mesh \u2503 \u2517\u2501 product_a \ud83e\udfa4\u2501\u2501\u2501 Instances for product_a \u2503 \u2517\u2501 instance_a \ud83e\udfa4\u2501\u2501\u2501 Some product_a's instance, here called \"instance_a\" \u2503 \u2523\u2501 config.yaml \ud83e\udfa4\u2501\u2501\u2501 Non-sensitive configuration for instance_a \u2503 \u2517\u2501 plugs \ud83e\udfa4\u2501\u2501\u2501 Plugs whose source is instance_a \u2503 \u2517\u2501 instance_b \ud83e\udfa4\u2501\u2501\u2501 Plugs whose destination is instance_b \u2503 \u2517\u2501 event_consumer_pull.yaml \ud83e\udfa4\u2501\u2501\u2501 Config for plug instance_a -[events]-> instance_b in pull mode \u2503 \u2517\u2501 product_b \u2503 \u2517\u2501 instance_product_b \u2503 \u2517\u2501 ... \u2523\u2501 secrets.gpg \ud83e\udfa4\u2501\u2501\u2501 GPG-encrypted store of all instances' secrets This is a minimal example, your project may contain additional files, such as .gitignore, README.md and other documentation or scripts for automating stuff.","title":"Wrap-up with Meshroom project structure"},{"location":"tutorial/","text":"Tutorial \u00b6 This tutorial guides you through integrating a dummy product in a meshroom project's capabilities graph instantiating a mesh setting up this mesh with real product tenants playing and inspect data flowing through it We take an hypothetical intelligence-driven EDR called \"myedr\" as the examplar product to showcase the Meshroom CLI and underlying concepts. 0. Setup a meshroom project \u00b6 A meshroom project is a git-backed directory on your computer. Let's setup one via meshroom init <path> cd <path> This has scaffolded a local git repo with two directories: products and instances We can list list our Products and Instances using meshroom list products meshroom list instances which confirms we have no products and no instances yet. 1. Gather knowledge about existing products \u00b6 In Meshroom's spirit, users may have already shared products definitions via, say, github.com, so you can browse public shared meshroom repos for products of interest to build your mesh. Imagine we want to incorporate a Sekoia.io SOC platform tenant into our mesh. We can leverage existing definitions from https://github.com/opencybersecurityalliance/meshroom/tree/master/products/sekoia , by simply copying the subdirectory to our project's products/ folder: mkdir -p tmp curl -L -o tmp.tar.gz https://github.com/opencybersecurityalliance/meshroom/tarball/master tar -xzf tmp.tar.gz -C tmp mv tmp/*/example/products/sekoia products/sekoia rm -rf tmp tmp.tar.gz Happily, the sekoia product contains @pull hooks, allowing us to gather from Sekoia's official catalog the whole set of integrations available between Sekoia.io and 3rd-party products (here, so-called intake formats and playbook actions). Calling meshroom pull sekoia yields dozen of new products along with their own capabilities to the extent of what Sekoia.io can interop with. You'd probably need to gather and pull more product knowledge to enrich those 3rd-party product definitions and reach a sufficiently large and accurate capabilities graph to start instantiating a mesh from it. meshroom list products now shows many products available for instanciation. 2. Integrate your product \u00b6 This tutorial assumes we're a vendor of a new product that didn't get a meshroom definition yet. So let's create it from scratch, or better, using one of the provided product capabilities templates, found under https://github.com/opencybersecurityalliance/meshroom/tree/master/meshroom/templates/products meshroom create product myedr --from edr This created and scaffolded the folder products/myedr , with a draft definition.yaml and several other files. Of course, this is not enough to fully express myedr's full interop surface, but can be considered as a good starting point: some typical capabilities of a standard EDR have been automatically added to definition.yaml (such as an events consumer, an alerts producer, a containment executor, etc ). some basic hooks have been set in boilerplate files, ready for your own implementation to define how the myedr instance can be remotely provisioned and controlled. Since myedr is advertised as intelligence-driven, let's add three more capabilities, by editing its definition.yaml : consumes: threats: - format: stix mode: push produces: threats: - format: stix mode: pull executes: search_threat: - {} We just added: a capability to consume the threats topic in push mode (meaning that producers will actively call our myedr instance to provide original CTI data to it), following the well-known STIX standard. a capability to produce threats in pull mode (that is, 3rd-parties will have to query an API GET endpoint to obtain CTI from our myedr instance), again as STIX bundles. an execution capability for search_threat action, which by default works in push mode (triggers must make an active call to this executor to perform the action). No particular format constraint is set for it, 3rd-parties will have to figure out the expected payload to send to get a successful search. Let's assume that while the CTI production and consumption APIs are builtin in myedr, the threat search isn't available via API out-of-the-box. But myedr exposes a plugin mechanism to add such new external surface. We can then implement a @setup hook that will leverage this mechanism to automate the setup of our search_threat capabilities on a live myedr instance: Create the products/myedr/search_threat.py file containing from meshroom.decorators import setup_executor from meshroom.model import Integration, Plug, Instance @setup_executor(\"search_threat\") def setup_threat_search_api_via_myedr_plugin(integration: Integration, plug: Plug, instance: Instance): some_value = instance.settings.get(\"some_setting\") some_secret = plug.get_secret(\"SOME_SECRET\") api_key = instance.get_secret(\"API_KEY\") raise NotImplementedError(\"Implement the setup mechanism here\") We'll certainly have to implement the actual python logic (using HTTP requests libraries, or whatever is required to programmatically automate the configuration of a myedr plugin). Notice the .get_secret methods on the Plug and Instance objects: they allow you to securely store and retrieve sensitive configuration tokens to remotely operate your Instances. Integrations, Instances and Plugs can define arbitrary settings in their definition.yaml so that users get prompted for necessary values upon meshroom up , interactively. Let's add those required secrets and settings to our product's definition.yaml settings: - name: API_KEY secret: true - name: some_setting default: whatever This tells meshroom that any Instance of our myedr Product will require an API_KEY, stored securely, and an optional some_setting configuration parameter, prompted upon meshroom add when creating the said Instances. We may also require settings specific for myedr to interop with a particular 3rd-party, say, Sekoia.io Let's create a suitable Integration for that: meshroom create integration myedr sekoia search_threat executor This created a search_threat_executor.yaml manifest under products/myedr/integrations/sekoia/ to hold the integration-specific settings, in the same way we did at Product level. We can then add a settings: section akin to the Product's one. Upon meshroom plug search_threat some_sekoia_instance some_myedr_instance , because myedr has defined specific settings for the executor end of this Plug, the user we'll be prompted for necessary values. We thus demonstrated the basic concepts of: hooks product and integration manifests with settings how settings and secrets get prompted at meshroom add and meshroom plug . Note that you can (re-)configure those settings using meshroom configure , e.g. , when you'll instantiate your mesh on a different information system We can confirm the existence of our new product and integrations via meshroom list products mye meshroom list integrations myedr 3. Create a mesh \u00b6 We'll create a basic mesh of 2 Instances: a Sekoia.io instance called \"mysekoia\" a myedr instance called \"myedr\" (same name as the corresponding product) meshroom add sekoia mysekoia meshroom add myedr Each call will prompt you for the required secrets and settings. At this stage, nothing is submitted yet to the actual tenants, meshroom only created the instances/sekoia/mysekoia/... files and wrote all secrets to secrets.gpg , ready for calling meshroom up Now, let's plug both products, so that mysekoia can consume myedr's events and myedr can execute mysekoia's queries for threat searches. meshroom plug events myedr mysekoia meshroom plug search_threat mysekoia myedr Oh no ! Meshroom CLI tells us that it can't find an integration for the trigger side of the second plug. Indeed, we've defined how to setup a myedr plugin to execute threat searches, but no Sekoia.io integration to actually trigger it from Sekoia. Let's fix that meshroom create integration sekoia myedr search_threat trigger --mode=push and confirm it worked meshroom list integrations sekoia myedr Contrarily to the previous call to meshroom create integration , this has created many files under the products/sekoia/integrations/myedr/ folder, where we may recognize an almost complete Sekoia.io custom playbook action as one can find examples at https://github.com/SEKOIA-IO/automation-library . This integration has been automatically scaffolded because Sekoia.io's vendor has defined a @scaffold hook for this kind of trigger. This hook generated all the boilerplate code required to build a custom playbook action that will trigger executions on 3rd-party APIs. All we need to do is to actually implement the TODOs left in the boilerplate. We won't cover this specific business here, but once you've coded your own logic, you can call again meshroom plug search_threat mysekoia myedr which should now succeed ! meshroom list instances meshroom list plugs should then show 2 instances and 2 plugs connecting them. We're done with the mesh creation part of this tutorial, it's now time to give it life... 4. Meshroom up \ud83c\udf89 ! \u00b6 Once you get a valid and satisfactory mesh of Instances and Plugs, you're ready to call meshroom up As for a docker compose stack, this command should be enough to setup and configure all your tenants, and connect the required interops to make them communicate according to the mesh's graph. Sometimes, meshroom up will prompt for additional settings and secret required for the runtime. Another similary with docker compose or terraform stacks is that meshroom up is idempotent: if the mesh is already up, meshroom will tell you resources are already up. If only part of them are up, meshroom will setup those who are down, etc . To check everything works as expected, we can use two handy commands : meshroom produce events myedr mysekoia and meshroom watch events myedr mysekoia The first one will read lines from standard input and send them through myedr-[events]->mysekoia 's plug, so that mysekoia can consume some test events. The second command will wait for mysekoia instance to receive those events and will print them to standard output. Those commands are available thanks to the @produce and @consume hooks implemented in Sekoia's product definition. One is responsible for the programmatic emulation of data flowing to an integration, the other is reponsible for watching data as received by the instance to assess that the plug correctly route well-formed data to the destination product. @produce hook may be defined on both the producer and consumer side of an integration: if the producer defines a @produce hook it takes precedence over the consumer's one, the latter's role being to emulate data flowing to it, instead of sending data from the real producer. Similarly, the @consume hook may be defined by both the producer and the consumer: if the consumer defines it, it takes precedence over the producer's one, thus reflecting what was really received by the destination product, otherwise we fallback to the producer's one that only prints what is flowing out of the producer without guaranteeing that data is actually received at consumer side. Here, we left the destination product without @produce and @consume hooks, so we emulate data coming from myedr (meshroom generates this flow instead of really creating the data from myedr's output) but firmly assess this data is correctly received and parsed by mysekoia. 5. Meshroom down \u00b6 To make our mesh work, our instances have been automatically provisionned by meshroom up with plugins, configurations, etc . You may want to shutdown those capabilities and leave them in a clean state. Just call meshroom down and your mesh setup should have been withdrawn from your products tenants. Again, this works via hooks: your myedr product should define a @teardown hook taking care of programmatically cleaning the plugs. 6. Meshroom publish \u00b6 Finally, you may want to publicly release and share your mesh, and perhaps even contribute your developed integrations to the vendor's official integrations catalog. The first stage is to simply commit your git-backed meshroom project. By pushing it to github, every products, integrations and mesh definitions are versioned and pullable by your colleagues. They will be able to instantiate the mesh on a different information system as long as they run meshroom configure ... to adapt the settings and secrets to their own environment. Of course, because secrets are stored in a GPG-encrypted file, you may also share it with colleagues using their GPG key, as you would do with a vault or secrets bundle sharing utility. The second stage is to promote your integration as public contributions to the vendor's official catalog. For that matter, the vendor must have defined suitable @publish hooks for the topics of interest, so that the integration is turned into a valid package for uploading. In this tutorial, we know that Sekoia vendor has defined a @publish hook for triggers, that publishes individual triggers as standalone sekoia.io playbook modules for use in their playbook automation workflows. Simply call meshroom publish sekoia myedr search_threats and you should get a Github PR to https://github.com/SEKOIA-IO/automation-library ready for review by Sekoia.io's integrators. By the way, you can also play the trigger from command line via meshroom trigger search_threats mysekoia myedr -p <param>=<value> ... to test the trigger/executor relationship, as long as the vendor has defined a @trigger hook for the topic (or a generic one of course, which is the case for sekoia.io playbook actions). 7. Participate into building a community-driven global capability graph \u00b6 Naturally, it would be sad if your integration work remains under your sole ownership. Sharing with friends and colleague is something, but contributing to the global capability graph hosted at github.com/oxa/TODO would make everyone so happy ! Thank you in advance and happy meshrooming ! \ud83d\udc4b","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"This tutorial guides you through integrating a dummy product in a meshroom project's capabilities graph instantiating a mesh setting up this mesh with real product tenants playing and inspect data flowing through it We take an hypothetical intelligence-driven EDR called \"myedr\" as the examplar product to showcase the Meshroom CLI and underlying concepts.","title":"Tutorial"},{"location":"tutorial/#0-setup-a-meshroom-project","text":"A meshroom project is a git-backed directory on your computer. Let's setup one via meshroom init <path> cd <path> This has scaffolded a local git repo with two directories: products and instances We can list list our Products and Instances using meshroom list products meshroom list instances which confirms we have no products and no instances yet.","title":"0. Setup a meshroom project"},{"location":"tutorial/#1-gather-knowledge-about-existing-products","text":"In Meshroom's spirit, users may have already shared products definitions via, say, github.com, so you can browse public shared meshroom repos for products of interest to build your mesh. Imagine we want to incorporate a Sekoia.io SOC platform tenant into our mesh. We can leverage existing definitions from https://github.com/opencybersecurityalliance/meshroom/tree/master/products/sekoia , by simply copying the subdirectory to our project's products/ folder: mkdir -p tmp curl -L -o tmp.tar.gz https://github.com/opencybersecurityalliance/meshroom/tarball/master tar -xzf tmp.tar.gz -C tmp mv tmp/*/example/products/sekoia products/sekoia rm -rf tmp tmp.tar.gz Happily, the sekoia product contains @pull hooks, allowing us to gather from Sekoia's official catalog the whole set of integrations available between Sekoia.io and 3rd-party products (here, so-called intake formats and playbook actions). Calling meshroom pull sekoia yields dozen of new products along with their own capabilities to the extent of what Sekoia.io can interop with. You'd probably need to gather and pull more product knowledge to enrich those 3rd-party product definitions and reach a sufficiently large and accurate capabilities graph to start instantiating a mesh from it. meshroom list products now shows many products available for instanciation.","title":"1. Gather knowledge about existing products"},{"location":"tutorial/#2-integrate-your-product","text":"This tutorial assumes we're a vendor of a new product that didn't get a meshroom definition yet. So let's create it from scratch, or better, using one of the provided product capabilities templates, found under https://github.com/opencybersecurityalliance/meshroom/tree/master/meshroom/templates/products meshroom create product myedr --from edr This created and scaffolded the folder products/myedr , with a draft definition.yaml and several other files. Of course, this is not enough to fully express myedr's full interop surface, but can be considered as a good starting point: some typical capabilities of a standard EDR have been automatically added to definition.yaml (such as an events consumer, an alerts producer, a containment executor, etc ). some basic hooks have been set in boilerplate files, ready for your own implementation to define how the myedr instance can be remotely provisioned and controlled. Since myedr is advertised as intelligence-driven, let's add three more capabilities, by editing its definition.yaml : consumes: threats: - format: stix mode: push produces: threats: - format: stix mode: pull executes: search_threat: - {} We just added: a capability to consume the threats topic in push mode (meaning that producers will actively call our myedr instance to provide original CTI data to it), following the well-known STIX standard. a capability to produce threats in pull mode (that is, 3rd-parties will have to query an API GET endpoint to obtain CTI from our myedr instance), again as STIX bundles. an execution capability for search_threat action, which by default works in push mode (triggers must make an active call to this executor to perform the action). No particular format constraint is set for it, 3rd-parties will have to figure out the expected payload to send to get a successful search. Let's assume that while the CTI production and consumption APIs are builtin in myedr, the threat search isn't available via API out-of-the-box. But myedr exposes a plugin mechanism to add such new external surface. We can then implement a @setup hook that will leverage this mechanism to automate the setup of our search_threat capabilities on a live myedr instance: Create the products/myedr/search_threat.py file containing from meshroom.decorators import setup_executor from meshroom.model import Integration, Plug, Instance @setup_executor(\"search_threat\") def setup_threat_search_api_via_myedr_plugin(integration: Integration, plug: Plug, instance: Instance): some_value = instance.settings.get(\"some_setting\") some_secret = plug.get_secret(\"SOME_SECRET\") api_key = instance.get_secret(\"API_KEY\") raise NotImplementedError(\"Implement the setup mechanism here\") We'll certainly have to implement the actual python logic (using HTTP requests libraries, or whatever is required to programmatically automate the configuration of a myedr plugin). Notice the .get_secret methods on the Plug and Instance objects: they allow you to securely store and retrieve sensitive configuration tokens to remotely operate your Instances. Integrations, Instances and Plugs can define arbitrary settings in their definition.yaml so that users get prompted for necessary values upon meshroom up , interactively. Let's add those required secrets and settings to our product's definition.yaml settings: - name: API_KEY secret: true - name: some_setting default: whatever This tells meshroom that any Instance of our myedr Product will require an API_KEY, stored securely, and an optional some_setting configuration parameter, prompted upon meshroom add when creating the said Instances. We may also require settings specific for myedr to interop with a particular 3rd-party, say, Sekoia.io Let's create a suitable Integration for that: meshroom create integration myedr sekoia search_threat executor This created a search_threat_executor.yaml manifest under products/myedr/integrations/sekoia/ to hold the integration-specific settings, in the same way we did at Product level. We can then add a settings: section akin to the Product's one. Upon meshroom plug search_threat some_sekoia_instance some_myedr_instance , because myedr has defined specific settings for the executor end of this Plug, the user we'll be prompted for necessary values. We thus demonstrated the basic concepts of: hooks product and integration manifests with settings how settings and secrets get prompted at meshroom add and meshroom plug . Note that you can (re-)configure those settings using meshroom configure , e.g. , when you'll instantiate your mesh on a different information system We can confirm the existence of our new product and integrations via meshroom list products mye meshroom list integrations myedr","title":"2. Integrate your product"},{"location":"tutorial/#3-create-a-mesh","text":"We'll create a basic mesh of 2 Instances: a Sekoia.io instance called \"mysekoia\" a myedr instance called \"myedr\" (same name as the corresponding product) meshroom add sekoia mysekoia meshroom add myedr Each call will prompt you for the required secrets and settings. At this stage, nothing is submitted yet to the actual tenants, meshroom only created the instances/sekoia/mysekoia/... files and wrote all secrets to secrets.gpg , ready for calling meshroom up Now, let's plug both products, so that mysekoia can consume myedr's events and myedr can execute mysekoia's queries for threat searches. meshroom plug events myedr mysekoia meshroom plug search_threat mysekoia myedr Oh no ! Meshroom CLI tells us that it can't find an integration for the trigger side of the second plug. Indeed, we've defined how to setup a myedr plugin to execute threat searches, but no Sekoia.io integration to actually trigger it from Sekoia. Let's fix that meshroom create integration sekoia myedr search_threat trigger --mode=push and confirm it worked meshroom list integrations sekoia myedr Contrarily to the previous call to meshroom create integration , this has created many files under the products/sekoia/integrations/myedr/ folder, where we may recognize an almost complete Sekoia.io custom playbook action as one can find examples at https://github.com/SEKOIA-IO/automation-library . This integration has been automatically scaffolded because Sekoia.io's vendor has defined a @scaffold hook for this kind of trigger. This hook generated all the boilerplate code required to build a custom playbook action that will trigger executions on 3rd-party APIs. All we need to do is to actually implement the TODOs left in the boilerplate. We won't cover this specific business here, but once you've coded your own logic, you can call again meshroom plug search_threat mysekoia myedr which should now succeed ! meshroom list instances meshroom list plugs should then show 2 instances and 2 plugs connecting them. We're done with the mesh creation part of this tutorial, it's now time to give it life...","title":"3. Create a mesh"},{"location":"tutorial/#4-meshroom-up","text":"Once you get a valid and satisfactory mesh of Instances and Plugs, you're ready to call meshroom up As for a docker compose stack, this command should be enough to setup and configure all your tenants, and connect the required interops to make them communicate according to the mesh's graph. Sometimes, meshroom up will prompt for additional settings and secret required for the runtime. Another similary with docker compose or terraform stacks is that meshroom up is idempotent: if the mesh is already up, meshroom will tell you resources are already up. If only part of them are up, meshroom will setup those who are down, etc . To check everything works as expected, we can use two handy commands : meshroom produce events myedr mysekoia and meshroom watch events myedr mysekoia The first one will read lines from standard input and send them through myedr-[events]->mysekoia 's plug, so that mysekoia can consume some test events. The second command will wait for mysekoia instance to receive those events and will print them to standard output. Those commands are available thanks to the @produce and @consume hooks implemented in Sekoia's product definition. One is responsible for the programmatic emulation of data flowing to an integration, the other is reponsible for watching data as received by the instance to assess that the plug correctly route well-formed data to the destination product. @produce hook may be defined on both the producer and consumer side of an integration: if the producer defines a @produce hook it takes precedence over the consumer's one, the latter's role being to emulate data flowing to it, instead of sending data from the real producer. Similarly, the @consume hook may be defined by both the producer and the consumer: if the consumer defines it, it takes precedence over the producer's one, thus reflecting what was really received by the destination product, otherwise we fallback to the producer's one that only prints what is flowing out of the producer without guaranteeing that data is actually received at consumer side. Here, we left the destination product without @produce and @consume hooks, so we emulate data coming from myedr (meshroom generates this flow instead of really creating the data from myedr's output) but firmly assess this data is correctly received and parsed by mysekoia.","title":"4. Meshroom up \ud83c\udf89 !"},{"location":"tutorial/#5-meshroom-down","text":"To make our mesh work, our instances have been automatically provisionned by meshroom up with plugins, configurations, etc . You may want to shutdown those capabilities and leave them in a clean state. Just call meshroom down and your mesh setup should have been withdrawn from your products tenants. Again, this works via hooks: your myedr product should define a @teardown hook taking care of programmatically cleaning the plugs.","title":"5. Meshroom down"},{"location":"tutorial/#6-meshroom-publish","text":"Finally, you may want to publicly release and share your mesh, and perhaps even contribute your developed integrations to the vendor's official integrations catalog. The first stage is to simply commit your git-backed meshroom project. By pushing it to github, every products, integrations and mesh definitions are versioned and pullable by your colleagues. They will be able to instantiate the mesh on a different information system as long as they run meshroom configure ... to adapt the settings and secrets to their own environment. Of course, because secrets are stored in a GPG-encrypted file, you may also share it with colleagues using their GPG key, as you would do with a vault or secrets bundle sharing utility. The second stage is to promote your integration as public contributions to the vendor's official catalog. For that matter, the vendor must have defined suitable @publish hooks for the topics of interest, so that the integration is turned into a valid package for uploading. In this tutorial, we know that Sekoia vendor has defined a @publish hook for triggers, that publishes individual triggers as standalone sekoia.io playbook modules for use in their playbook automation workflows. Simply call meshroom publish sekoia myedr search_threats and you should get a Github PR to https://github.com/SEKOIA-IO/automation-library ready for review by Sekoia.io's integrators. By the way, you can also play the trigger from command line via meshroom trigger search_threats mysekoia myedr -p <param>=<value> ... to test the trigger/executor relationship, as long as the vendor has defined a @trigger hook for the topic (or a generic one of course, which is the case for sekoia.io playbook actions).","title":"6. Meshroom publish"},{"location":"tutorial/#7-participate-into-building-a-community-driven-global-capability-graph","text":"Naturally, it would be sad if your integration work remains under your sole ownership. Sharing with friends and colleague is something, but contributing to the global capability graph hosted at github.com/oxa/TODO would make everyone so happy ! Thank you in advance and happy meshrooming ! \ud83d\udc4b","title":"7. Participate into building a community-driven global capability graph"},{"location":"commands/add/","text":"meshroom add \u00b6 Usage meshroom add [OPTIONS] PRODUCT [NAME] Add a new Instance to the mesh for a given Product. You may optionnally specify a [NAME] . If not, the new Instance will get the same name as its Product. The new instance's configuration will by saved to products/<PRODUCT>/[NAME]/config.yml in your meshroom project tree. Options \u00b6 option description -s, --read-secret TEXT Read a one-line secret from stdin (can be supplied multiple times to read several secrets, one per line)","title":"meshroom add"},{"location":"commands/add/#meshroom-add","text":"Usage meshroom add [OPTIONS] PRODUCT [NAME] Add a new Instance to the mesh for a given Product. You may optionnally specify a [NAME] . If not, the new Instance will get the same name as its Product. The new instance's configuration will by saved to products/<PRODUCT>/[NAME]/config.yml in your meshroom project tree.","title":"meshroom add"},{"location":"commands/add/#options","text":"option description -s, --read-secret TEXT Read a one-line secret from stdin (can be supplied multiple times to read several secrets, one per line)","title":"Options"},{"location":"commands/configure/","text":"meshroom configure \u00b6 Usage meshroom configure [OPTIONS] INSTANCE Reconfigure an existing Instance, prompting for the settings and secrets declared by its Product definition. Options \u00b6 option description -s, --read-secret TEXT Read a one-line secret from stdin (can be supplied multiple times to read several secrets, one per line)","title":"meshroom configure"},{"location":"commands/configure/#meshroom-configure","text":"Usage meshroom configure [OPTIONS] INSTANCE Reconfigure an existing Instance, prompting for the settings and secrets declared by its Product definition.","title":"meshroom configure"},{"location":"commands/configure/#options","text":"option description -s, --read-secret TEXT Read a one-line secret from stdin (can be supplied multiple times to read several secrets, one per line)","title":"Options"},{"location":"commands/create_integration/","text":"meshroom create integration \u00b6 Usage meshroom create integration [OPTIONS] PRODUCT TARGET_PRODUCT TOPIC {consumer|producer|trigger|executor} Scaffold a new Integration with the given role (consumer, producer, trigger or executor). A consumer is the complementary integration of a producer. An executor is the complementary integration of a trigger. An integration always consume/produce or trigger/execute one given topic , in a predefined mode ( push or pull ) If the PRODUCT declares a @scaffold hook, it will be called to generate the integration's boilerplate. Options \u00b6 option description --mode [push|pull] Set the operation mode of the integration. Push means the producer is active and the consumer is passive, while Pull means the producer is passive and the consumer is active -f, --format TEXT Set the data format supported by this integration. Only integrations with identical format or format-agnostic one will match this integration","title":"meshroom create integration"},{"location":"commands/create_integration/#meshroom-create-integration","text":"Usage meshroom create integration [OPTIONS] PRODUCT TARGET_PRODUCT TOPIC {consumer|producer|trigger|executor} Scaffold a new Integration with the given role (consumer, producer, trigger or executor). A consumer is the complementary integration of a producer. An executor is the complementary integration of a trigger. An integration always consume/produce or trigger/execute one given topic , in a predefined mode ( push or pull ) If the PRODUCT declares a @scaffold hook, it will be called to generate the integration's boilerplate.","title":"meshroom create integration"},{"location":"commands/create_integration/#options","text":"option description --mode [push|pull] Set the operation mode of the integration. Push means the producer is active and the consumer is passive, while Pull means the producer is passive and the consumer is active -f, --format TEXT Set the data format supported by this integration. Only integrations with identical format or format-agnostic one will match this integration","title":"Options"},{"location":"commands/create_product/","text":"meshroom create product \u00b6 Usage meshroom create product [OPTIONS] NAME Scaffold a new Product, optionally from a template found under templates/ , into products/<NAME> folder. If no template is passed the produce is created empty. If a template is passed the template is interpolated to the product's directory Options \u00b6 option description --from TEMPLATE Path to a templates/ subdirectory to scaffold the product from","title":"meshroom create product"},{"location":"commands/create_product/#meshroom-create-product","text":"Usage meshroom create product [OPTIONS] NAME Scaffold a new Product, optionally from a template found under templates/ , into products/<NAME> folder. If no template is passed the produce is created empty. If a template is passed the template is interpolated to the product's directory","title":"meshroom create product"},{"location":"commands/create_product/#options","text":"option description --from TEMPLATE Path to a templates/ subdirectory to scaffold the product from","title":"Options"},{"location":"commands/down/","text":"meshroom down \u00b6 Usage meshroom down [OPTIONS] [INSTANCE] [TARGET_INSTANCE] [TOPIC] [[push|pull]] Unconfigure all Instances, a single Instance or a single Plug.","title":"meshroom down"},{"location":"commands/down/#meshroom-down","text":"Usage meshroom down [OPTIONS] [INSTANCE] [TARGET_INSTANCE] [TOPIC] [[push|pull]] Unconfigure all Instances, a single Instance or a single Plug.","title":"meshroom down"},{"location":"commands/execute/","text":"meshroom execute \u00b6 Usage meshroom execute [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Execute an executor exposed by a Plug, either via the plug's source integration's @trigger hook, or by directly calling the destination integration's @execute hook. * If the DST_INSTANCE is not set, the executor side is triggered by calling its @execute hook if defined * If the DST_INSTANCE is set, the trigger side is triggered by calling its @trigger hook if defined If no corresponding hook is defined on the underlying products, this command fails. Options \u00b6 option description --mode [push|pull] Pick the plug that uses the given operation mode -p, --param FIELD=VALUE Pass arguments to the @execute / @trigger hooks","title":"meshroom execute"},{"location":"commands/execute/#meshroom-execute","text":"Usage meshroom execute [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Execute an executor exposed by a Plug, either via the plug's source integration's @trigger hook, or by directly calling the destination integration's @execute hook. * If the DST_INSTANCE is not set, the executor side is triggered by calling its @execute hook if defined * If the DST_INSTANCE is set, the trigger side is triggered by calling its @trigger hook if defined If no corresponding hook is defined on the underlying products, this command fails.","title":"meshroom execute"},{"location":"commands/execute/#options","text":"option description --mode [push|pull] Pick the plug that uses the given operation mode -p, --param FIELD=VALUE Pass arguments to the @execute / @trigger hooks","title":"Options"},{"location":"commands/init/","text":"meshroom init \u00b6 Usage meshroom init [PATH] Initializes a new Meshroom project under PATH .","title":"meshroom init"},{"location":"commands/init/#meshroom-init","text":"Usage meshroom init [PATH] Initializes a new Meshroom project under PATH .","title":"meshroom init"},{"location":"commands/plug/","text":"meshroom plug \u00b6 Usage meshroom plug [OPTIONS] TOPIC SRC_INSTANCE DST_INSTANCE Create a Plug between two instances. A compatible producer/consumer or trigger/executor pair of integrations must exist on the corresponding source and destination products for the given topic. Such mathcing integrations may be either: * explicitly implemented as integrations with setup hooks having own_both=False * explicitly implemented as an integration with a setup hook having own_both=True by one of the products * implicitly defined via generic setup hooks on one or both products. Note This doesn't setup the corresponding interop to your real product instance yet, it simply add its declaration to the project, ready for a subsequent meshroom up . Options \u00b6 option description --mode [push|pull] Force the given plug operation mode","title":"meshroom plug"},{"location":"commands/plug/#meshroom-plug","text":"Usage meshroom plug [OPTIONS] TOPIC SRC_INSTANCE DST_INSTANCE Create a Plug between two instances. A compatible producer/consumer or trigger/executor pair of integrations must exist on the corresponding source and destination products for the given topic. Such mathcing integrations may be either: * explicitly implemented as integrations with setup hooks having own_both=False * explicitly implemented as an integration with a setup hook having own_both=True by one of the products * implicitly defined via generic setup hooks on one or both products. Note This doesn't setup the corresponding interop to your real product instance yet, it simply add its declaration to the project, ready for a subsequent meshroom up .","title":"meshroom plug"},{"location":"commands/plug/#options","text":"option description --mode [push|pull] Force the given plug operation mode","title":"Options"},{"location":"commands/produce/","text":"meshroom produce \u00b6 Usage meshroom produce [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Produce data through a Plug, either using the plug producer's @produce hook or directly calling the plug's consumer's @produce hook. Options \u00b6 option description --mode [push|pull] Pick the plug with given operation mode","title":"meshroom produce"},{"location":"commands/produce/#meshroom-produce","text":"Usage meshroom produce [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Produce data through a Plug, either using the plug producer's @produce hook or directly calling the plug's consumer's @produce hook.","title":"meshroom produce"},{"location":"commands/produce/#options","text":"option description --mode [push|pull] Pick the plug with given operation mode","title":"Options"},{"location":"commands/publish/","text":"meshroom publish \u00b6 Usage meshroom publish [OPTIONS] [PRODUCT] [TARGET_PRODUCT] [TOPIC] [[consumer|producer|trigger|executor]] Publish a specific integration, a given product's integrations or all integrations at once to their respective products official integrations catalog, according to the @publish hook defined by their vendors. Options \u00b6 option description -m, --mode [push|pull] Restrict to integrations of given operation mode -f, --format TEXT Restrict to integration conveying the given format","title":"meshroom publish"},{"location":"commands/publish/#meshroom-publish","text":"Usage meshroom publish [OPTIONS] [PRODUCT] [TARGET_PRODUCT] [TOPIC] [[consumer|producer|trigger|executor]] Publish a specific integration, a given product's integrations or all integrations at once to their respective products official integrations catalog, according to the @publish hook defined by their vendors.","title":"meshroom publish"},{"location":"commands/publish/#options","text":"option description -m, --mode [push|pull] Restrict to integrations of given operation mode -f, --format TEXT Restrict to integration conveying the given format","title":"Options"},{"location":"commands/pull/","text":"meshroom pull \u00b6 Usage meshroom pull [OPTIONS] PRODUCT Pull a product's official integrations catalog, importing all integrations by calling the product's @pull hooks","title":"meshroom pull"},{"location":"commands/pull/#meshroom-pull","text":"Usage meshroom pull [OPTIONS] PRODUCT Pull a product's official integrations catalog, importing all integrations by calling the product's @pull hooks","title":"meshroom pull"},{"location":"commands/remove/","text":"meshroom remove \u00b6 Usage meshroom remove [OPTIONS] INSTANCE [PRODUCT] Remove the given Instance from the mesh, optionnaly given its Product","title":"meshroom remove"},{"location":"commands/remove/#meshroom-remove","text":"Usage meshroom remove [OPTIONS] INSTANCE [PRODUCT] Remove the given Instance from the mesh, optionnaly given its Product","title":"meshroom remove"},{"location":"commands/trigger/","text":"meshroom trigger \u00b6 Usage meshroom trigger [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Trigger an trigger exposed by a Plug, either by calling the trigger's @trigger hook or directly the executor's @execute hooks: * If the DST_INSTANCE is not set, the executor side is triggered by calling its @execute hook if defined * If the DST_INSTANCE is set, the trigger side is triggered by calling its @trigger hook if defined If no corresponding hook is defined on the underlying products, this command fails. Options \u00b6 option description --mode [push|pull] Pick the plug that uses the given operation mode -p, --param FIELD=VALUE Pass arguments to the @execute / @trigger hooks","title":"meshroom trigger"},{"location":"commands/trigger/#meshroom-trigger","text":"Usage meshroom trigger [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Trigger an trigger exposed by a Plug, either by calling the trigger's @trigger hook or directly the executor's @execute hooks: * If the DST_INSTANCE is not set, the executor side is triggered by calling its @execute hook if defined * If the DST_INSTANCE is set, the trigger side is triggered by calling its @trigger hook if defined If no corresponding hook is defined on the underlying products, this command fails.","title":"meshroom trigger"},{"location":"commands/trigger/#options","text":"option description --mode [push|pull] Pick the plug that uses the given operation mode -p, --param FIELD=VALUE Pass arguments to the @execute / @trigger hooks","title":"Options"},{"location":"commands/unplug/","text":"meshroom unplug \u00b6 Usage meshroom unplug [OPTIONS] TOPIC SRC_INSTANCE DST_INSTANCE Removes a plug between two instances. Note This doesn't unprovision the corresponding interop, it simply removes its declaration from the project. Options \u00b6 option description --mode [push|pull] Restrict to the plug that uses the given operation mode","title":"meshroom unplug"},{"location":"commands/unplug/#meshroom-unplug","text":"Usage meshroom unplug [OPTIONS] TOPIC SRC_INSTANCE DST_INSTANCE Removes a plug between two instances. Note This doesn't unprovision the corresponding interop, it simply removes its declaration from the project.","title":"meshroom unplug"},{"location":"commands/unplug/#options","text":"option description --mode [push|pull] Restrict to the plug that uses the given operation mode","title":"Options"},{"location":"commands/up/","text":"meshroom up \u00b6 Usage meshroom up [OPTIONS] [INSTANCE] [TARGET_INSTANCE] [TOPIC] [[push|pull]] Setup all declared Instances, a single Instance or a single Plug, depending on the optional parameters passed. Instances and Plugs are setup according to their @setup hooks: * Plugs in push mode leveraging two integrations with no owns_both=True hooks will setup the consumer first, then the producer * Plugs in pull mode leveraging two integrations with no owns_both=True hooks will setup the prducer first, then the consumer * Plugs having a owns_both=True hook set on one of their integrations will setup this sole integrations, since owns_both=True tells the hooked product is responsible for setting up the whole link without configuring anything explicit on the 3rd-party instance.","title":"meshroom up"},{"location":"commands/up/#meshroom-up","text":"Usage meshroom up [OPTIONS] [INSTANCE] [TARGET_INSTANCE] [TOPIC] [[push|pull]] Setup all declared Instances, a single Instance or a single Plug, depending on the optional parameters passed. Instances and Plugs are setup according to their @setup hooks: * Plugs in push mode leveraging two integrations with no owns_both=True hooks will setup the consumer first, then the producer * Plugs in pull mode leveraging two integrations with no owns_both=True hooks will setup the prducer first, then the consumer * Plugs having a owns_both=True hook set on one of their integrations will setup this sole integrations, since owns_both=True tells the hooked product is responsible for setting up the whole link without configuring anything explicit on the 3rd-party instance.","title":"meshroom up"},{"location":"commands/watch/","text":"meshroom watch \u00b6 Usage meshroom watch [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Inspect data flowing through a Plug or a Instance. If DST_INSTANCE is passed, data flowing through the plug from INSTANCE to DST_INSTANCE on the TOPIC will be printed, one record per line. If DST_INSTANCE is unset, every message flowing to the INSTANCE for topic TOPIC (whichever the source of it) will be printed. Options \u00b6 option description --mode [push|pull] Restrict watch to plugs with the given operation mode","title":"meshroom watch"},{"location":"commands/watch/#meshroom-watch","text":"Usage meshroom watch [OPTIONS] TOPIC INSTANCE [DST_INSTANCE] Inspect data flowing through a Plug or a Instance. If DST_INSTANCE is passed, data flowing through the plug from INSTANCE to DST_INSTANCE on the TOPIC will be printed, one record per line. If DST_INSTANCE is unset, every message flowing to the INSTANCE for topic TOPIC (whichever the source of it) will be printed.","title":"meshroom watch"},{"location":"commands/watch/#options","text":"option description --mode [push|pull] Restrict watch to plugs with the given operation mode","title":"Options"}]}